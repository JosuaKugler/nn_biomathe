{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronale Netzwerke - Tutorial Teil 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. WIEDERHOLUNG: Typen neuronaler Netzwerke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Fully-Connected Neural Networks (FCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein __FCN__ (oder neuronale Netzwerke im Allgemeinen) kann als Sequenz spezifischer Schichten beschrieben werden. Diese Schichten, entsprechend der Position als _input_-, _output_- und _hidden layer_ bezeichnet, sind Kollektionen von Neuronen (siehe Bild). \n",
    "<img src=\"Bilder/fnc.jpeg\">\n",
    "Jedes Neuron hat bei einem __FCN__ eine Verbindung zu allen vorhergehenden und nachfolgenden Neuronen. Alle eingehenden (und die entsprechend ausgehenden) Verknüpfungen können beschrieben werden wie in folgendem Bild:\n",
    "<img src=\"Bilder/single_neuron.jpg\">\n",
    "Jede Verknüpfung hat ein kennzeichnendes Gewicht, welches dem entsprechenden Eingangssignal eine Wichtigkeit zuordnet. Diese Miniprodukte werden dann summiert und durch eine Aktivierungsfunktion $f$ geschickt.\n",
    "Somit führt jedes Neuron eine mathematische Operation der Form\n",
    "\n",
    "\\begin{equation}\n",
    "y = f\\left( b + \\sum_{i=1}^n w_ix_i \\right)\n",
    "\\end{equation}\n",
    "\n",
    "durch.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein __CNN__ ist eine Sammlung verschiedener _Kernels_ oder _Filter_ - kleine \"Pakete\" mit Gewichten, welche über das Bild geschoben (_gefaltet_) werden. Ziel ist es, das jedes einzelne Paket Pixelgruppen identifiziert, z.B. kleine Ecken und Linien in der ersten Schicht und komplizierte, kombinierte Strukturen in den Folgeschichten. Dies lässt sich gut an einem generellen Aufbaubeispiel verdeutlichen, z.B. hier:\n",
    "<img src=\"Bilder/cnn.png\">\n",
    "\n",
    "oder hier:\n",
    "\n",
    "<img src=\"Bilder/cnn2.png\">\n",
    "\n",
    "---\n",
    "\n",
    "Die _Kernel_ werden dabei entsprechenden folgendem Bild über das Bild geschoben um sog. __feature maps__ zu generieren; funktionale Bilder welche die Auftrittswahrscheinlichkeit eines vom entsprechenden _Kernel_ codierten _features_ (Eigenschaft) am entsprechenden Ort angeben:\n",
    "\n",
    "<img src=\"Bilder/conv_pic_example.png\">\n",
    "\n",
    "Häufig auftretend in solchen Strukturen sind __Pooling Layer__ , welche die vorhergehenden _feature maps_ zusammenfassen um Platz zu speichern und das Training zu beschleunigen. Ein solches _Layer_ ist definiert durch eine _Kernelgröße_, welche wie bei normalen _CNN_-Schichten über das Bild geschoben werden und dabei entsprechende Zusammenfassungsoperation durchführen, z.B. das Maximum oder das arithmetische Mittel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Umsetzung in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein solches Netzwerk effektiv und vor allem einfach implementieren zu können, verwenden wir die __PyTorch__-Bibliothek (Installationsinformationen siehe vorheriges Tutorial).\n",
    "\n",
    "Für ein _FCN_ sieht das beispielsweise so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "#torch.nn ist die Sammlung aller generellen Funktionen \n",
    "#eines neuronalen Netzwerkes, daher auch die Abküruzung nn.\n",
    "\n",
    "class FCN_Base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN_Base,self).__init__()\n",
    "        self.fcn1 = nn.Linear(784,30)\n",
    "        self.fcn2 = nn.Linear(30,30)\n",
    "        self.fcn3 = nn.Linear(30,10)\n",
    "        self.akt_func = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fcn1(x))\n",
    "        x = F.relu(self.fcn2(x))\n",
    "        x = self.akt_func(self.fcn3(x))\n",
    "        return x\n",
    "    \n",
    "#ODER\n",
    "\n",
    "FCN_Base_2 = torch.nn.Sequential(\n",
    "             torch.nn.Linear(784, 30), # Erste/Zweite Schicht: 784 Eingangsneuronen zu 30 \"versteckten\" Neuronen\n",
    "             torch.nn.ReLU(),          # Aktivierungsfunktion\n",
    "             torch.nn.Linear(30, 30),  # Zweite/Erste Schicht: 30 \"versteckte\" Neuronen gehen über zu 10 Ausgangsneuronen.\n",
    "             torch.nn.ReLU(),\n",
    "             torch.nn.Linear(30,10),\n",
    "             torch.nn.Softmax(dim=1)   # Ausgangsaktivierungsfunktion. Siehe vorheriges Tutorial.\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und für ein _CNN_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sowie für CNNs:\n",
    "\n",
    "class CNN_Base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Base,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)  # 26x26\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3) # 24x24\n",
    "        self.conv3 = nn.Conv2d(20, 30, kernel_size=3,padding=1)  # 12x12\n",
    "        self.conv4 = nn.Conv2d(30, 30, kernel_size=3,padding=1)  # 12x12\n",
    "        self.conv5 = nn.Conv2d(30, 50, kernel_size=3,padding=1) # 6x6        \n",
    "        self.conv6 = nn.Conv2d(50, 50, kernel_size=3,padding=1)# 6x6                \n",
    "        self.fc1 = nn.Linear(1800, 150)\n",
    "        self.fc2 = nn.Linear(150, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.out_act = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv2(self.conv1(x)), 2))\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv4(self.conv3(x)), 2))\n",
    "        x = F.leaky_relu(self.conv6(self.conv5(x)), 2)\n",
    "        x = x.view(-1, 1800)   #Hier ändern wir Bild- zu Vektorformat\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))        \n",
    "        x = self.fc3(x)\n",
    "        return self.out_act(x)\n",
    "\n",
    "#ODER\n",
    "\n",
    "class CNN_Base_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.conv_teil = nn.Sequential(\n",
    "                         nn.Conv2d(1,10,3),\n",
    "                         nn.Conv2d(10,20,3),\n",
    "                         nn.MaxPool2d(2),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(20,30,3),\n",
    "                         nn.Conv2d(30,30,3),\n",
    "                         nn.MaxPool2d(2),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(30,50,3),\n",
    "                         nn.Conv2d(50,50,3),\n",
    "                         nn.ReLU())\n",
    "        self.fcn_teil =  nn.Sequential(\n",
    "                         nn.Linear(1800,150),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(150,50),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(50,10),\n",
    "                         nn.Softmax(dim=1))\n",
    "    def forward(self,x):\n",
    "        x = self.conv_teil(x)\n",
    "        x = x.view(-1,1800)\n",
    "        x = self.fcn_teil(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das allgemeine Training können wir das entsprechende Skript des letzten Tutorials verwenden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3.1 Generelle Funktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNIST_Data_Provider(Dataset):\n",
    "    def __init__(self, all_image_paths, all_image_labels):\n",
    "        super(MNIST_Data_Provider, self).__init__()\n",
    "\n",
    "        self.all_image_paths, self.all_image_labels = all_image_paths, all_image_labels\n",
    "        self.transform_to_torch_tensor = transforms.ToTensor()\n",
    "        self.hot_list = np.eye(10).astype(int)     \n",
    "        \n",
    "    def one_hot(self, label):\n",
    "        return self.hot_list[label]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        loaded_image    = Image.open(self.all_image_paths[idx])\n",
    "        label_for_image = self.all_image_labels[idx]\n",
    "        \n",
    "        return self.transform_to_torch_tensor(loaded_image), label_for_image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_image_paths)\n",
    "    \n",
    "\n",
    "def get_image_paths(path_to_folder):\n",
    "    all_image_paths = []\n",
    "    all_labels      = []\n",
    "    for numberpath in os.listdir(path_to_folder):\n",
    "        if numberpath != \".DS_Store\" and '_' not in numberpath:\n",
    "            avail_img_paths = [x for x in os.listdir(path_to_folder+\"/\"+numberpath) if '._' not in x]\n",
    "            all_image_paths.extend([path_to_folder+\"/\"+numberpath+\"/\"+x for x in avail_img_paths])\n",
    "            all_labels.extend([int(numberpath) for _ in range(len(avail_img_paths))])\n",
    "    return all_image_paths, all_labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3.2 Trainings-Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\"\"\" Hyperparameter \"\"\"\n",
    "batch_size = 64\n",
    "n_epochs   = 2\n",
    "learning_rate = 0.0003\n",
    "train_validation_split = 0.8\n",
    "\n",
    "\n",
    "\"\"\" Aufsetzen der Datengeneratoren \"\"\"\n",
    "path_to_MNIST_dataset = os.getcwd()+\"/MNIST/trainingSet\"\n",
    "\n",
    "all_image_paths, all_image_labels = get_image_paths(path_to_MNIST_dataset)\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(all_image_paths)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(all_image_labels)\n",
    "\n",
    "split_idx = int(len(all_image_paths)*train_validation_split)\n",
    "\n",
    "training_img_paths = all_image_paths[:split_idx]\n",
    "training_labels    = all_image_labels[:split_idx]\n",
    "train_dataset = MNIST_Data_Provider(training_img_paths, training_labels)\n",
    "train_datagen = DataLoader(train_dataset, batch_size=batch_size,drop_last=True, shuffle=True, num_workers=1)\n",
    "\n",
    "validation_img_paths = all_image_paths[split_idx:]\n",
    "validation_labels    = all_image_labels[split_idx:]\n",
    "val_dataset = MNIST_Data_Provider(validation_img_paths, validation_labels)\n",
    "val_datagen = DataLoader(val_dataset, batch_size=batch_size, drop_last=True, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Laden des Netzes, Aufsetzen des Optimierers\"\"\"\n",
    "Net = CNN_Base()\n",
    "device = torch.device('cpu')\n",
    "# ### Im Falle ein GPU:\n",
    "# device = torch.device('cuda')\n",
    "_ = Net.to(device)\n",
    "#Oder: FCN_Base, FCN_Base_2, CNN_Base_2\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(Net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in Epoch 0...\n",
      "\t T-Progress: [101/525]\n",
      "\t T-Progress: [201/525]\n",
      "\t T-Progress: [301/525]\n",
      "\t T-Progress: [401/525]\n",
      "\t T-Progress: [501/525]\n",
      "\t V-Progress: [101/131]\n",
      "Results: T-Loss 0.02455 | T-Acc 88.9702% | V-Acc 0.0000%\n",
      "Training in Epoch 1...\n",
      "\t T-Progress: [101/525]\n",
      "\t T-Progress: [201/525]\n",
      "\t T-Progress: [301/525]\n",
      "\t T-Progress: [401/525]\n",
      "\t T-Progress: [501/525]\n",
      "\t V-Progress: [101/131]\n",
      "Results: T-Loss 0.02375 | T-Acc 94.0893% | V-Acc 0.0000%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Training & Validierung \"\"\"\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Training in Epoch {}...\".format(epoch))\n",
    "    \n",
    "    \"\"\" Hier startet das Training! \"\"\"\n",
    "    Net.train()\n",
    "    \n",
    "    train_avg_loss = 0\n",
    "    train_avg_acc  = 0\n",
    "    \n",
    "    data_coll = {\"t_acc\":[], \"v_acc\":[]}\n",
    "    for idx, (img,label) in enumerate(train_datagen):\n",
    "        img, label = img.to(device), label.to(device)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        ### Für FCNs\n",
    "        #output = Net(img.view(batch_size,-1))\n",
    "        output = Net(img)\n",
    "        \n",
    "        loss = F.cross_entropy(output, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct_guesses = output.cpu().detach().max(1)[1].eq(label.cpu().detach()).sum()\n",
    "        \n",
    "        train_avg_loss += loss.item()\n",
    "        train_avg_acc  += correct_guesses.numpy()\n",
    "        \n",
    "        if idx%100==0 and idx!=0:\n",
    "            print(\"\\t T-Progress: [{}/{}]\".format(idx+1,len(train_datagen)))\n",
    "\n",
    "    train_avg_loss = train_avg_loss*1./(batch_size*len(train_datagen))\n",
    "    train_avg_acc  = train_avg_acc*1./(batch_size*len(train_datagen))\n",
    "    \n",
    "    data_coll[\"t_acc\"].append(train_avg_acc)\n",
    "    \n",
    "    \n",
    "    \"\"\" Hier startet die Validierung \"\"\"\n",
    "    Net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_avg_acc = 0\n",
    "        for idx, (img,label) in enumerate(val_datagen):\n",
    "            img, label = Variable(img), Variable(label)\n",
    "\n",
    "            #output = Net(img.view(batch_size,-1))\n",
    "            output = Net(img)\n",
    "            correct_guesses = output.data.max(1)[1].eq(label.data).sum()\n",
    "\n",
    "            val_avg_acc  += correct_guesses\n",
    "\n",
    "            if idx%100==0 and idx!=0:\n",
    "                print(\"\\t V-Progress: [{}/{}]\".format(idx+1,len(val_datagen)))    \n",
    "\n",
    "        val_avg_acc = val_avg_acc*1./(batch_size*len(val_datagen))\n",
    "        data_coll[\"v_acc\"].append(val_avg_acc)    \n",
    "        print(\"Results: T-Loss {0:2.5f} | T-Acc {1:3.4f}% | V-Acc {2:3.4f}%\".format(train_avg_loss, train_avg_acc*100., val_avg_acc*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Netzwerke speichern\n",
    "Hier noch eine wichtige Erweiterung: Wenn die Gewichte des Netzwerk gespeichert werden sollen, um sie irgendwann nochmal wieder zu verwenden, bedient man sich einfach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(Net.state_dict(), _pfad_zum_speicherplatz_mit_namen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein Netzwerk mit den entsprechenden Gewichten auszustatten, verwendet man:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net.load_state_dict(torch.load(_pfad_zum_speicherplatz_mit_namen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Wichtig__: Die Netzwerkstruktur muss die Gleiche sein, um sie mit Gewichten ausstatten zu können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir dieses Netzwerk im Ordner `Netzwerke` speichern wollen, verwenden wir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "### Falls der Ordner Netzwerke nicht existiert, erstellen wir ihn:\n",
    "if not os.path.exists(os.getcwd()+'/Netzwerke'):\n",
    "    os.makedirs(os.getcwd()+'/Netzwerke')\n",
    "speichername = 'CNN_Version1'\n",
    "torch.save(Net.state_dict(), os.getcwd()+'/Netzwerke/'+speichername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und um unser Netzwerke wieder mit den passenden Gewichten auszustatten, verwendet man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net.load_state_dict(torch.load(os.getcwd()+'/Netzwerke/'+speichername))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einige neue extra Methoden für bessere Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unter <http://pytorch.org/docs/master/nn.html#> finden sich viele weitere Möglichkeiten, die Performance des Netzwerkes zu verbessern. Hier werden einige grundlegende Optionen aufgelistet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Parameter Normen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund der enormen Zahl an Parametern haben neuronale Netzwerke die Kapazität, sich den Trainingsdatensatz zu \"merken\". Das sorgt zwar für eine hohe Trainingsgenauigkeit, führt aber dazu das Vorhersagen außerhalb des Trainingssets unzuverlässig werden.\n",
    "\n",
    "Um dem entgegenzuwirken, bedient man sich verschiedener Methoden, welche alle unter den Schirm __Regularisierung__ fallen.\n",
    "\n",
    "Eine hiervon ist die Einführung von Parameternormen, welche Einschränkungen auf Netzwerkgewichte setzen, indem diese in die Kostenfunktion einbezogen werden:\n",
    "\n",
    "* `L2`-__Norm__: $L_{reg}(\\theta, \\textbf{x}, \\textbf{y}) = L(\\theta, \\textbf{x}, \\textbf{y}) + \\lambda \\cdot ||\\theta||^2_2 $\n",
    "* `L1`-__Norm__: $L_{reg}(\\theta, \\textbf{x}, \\textbf{y}) = L(\\theta, \\textbf{x}, \\textbf{y}) + \\lambda \\cdot ||\\theta||_2 $\n",
    "\n",
    "Um die Kostenfunktion zu minimieren, muss das Netzwerk lernen, mit hohen Gewichten sparsam umzugehen. Intuitiv bedeutet das, dass das Netzwerk auf einzelne Elemente keine extreme Gewichtung setzen kann. Methematisch lässt sich für $L2$-Normen, zumindest für einfache Netzwerke, zeigen dass Gewichtungen entlang Richtungen niedriger Krümmung auf der Kostenlandschaft gedrückt werden. \n",
    "\n",
    "Im Falle der $L1$-Normen können diese sogar auf $0$ gelegt werden.\n",
    "\n",
    "Der Hyperparameter gibt an, in welchem Maße man diese Zusatzkosten miteinbezogen werden sollen. Standardwerte hierfür liegen in den Bereichen $10^{-5}$.\n",
    "\n",
    "Die Implementierung in PyTorch erfolgt direkt über den Optimierungsalgorithmuses (`L2` entspricht `weight_decay`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(Net.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout beruht auf der `Bagging`-Idee, in welcher ein Algorithmus auf verschiedenen Stichproben der Trainingsdaten generiert werden.\n",
    "Die Implementation erfolgt, indem Neuronen für eine Trainingsiteration mit einer Wahrscheinlichkeit $p$ ausgeschaltet werden und den entsprechenden Input in dieser Iteration nicht \"sehen\". Zudem muss das Netzwerk lernen, mit den verbleibenden Gewichten sinnvolle Aussagen zu treffen, was der Entwicklung einzelner extremer Gewichtungen entgegenwirkt.\n",
    "\n",
    "Während der eigentlichen Vorhersagen muss man allerdings alle Gewichte mit dem Faktor $\\frac{1}{1-p}$ skalieren \n",
    "(PyTorch macht das automatisch), da bei $p$ ausgeschaltenen Neuronen während dem Training sich der Erwartungswert verschiebt wenn alle auf einmal verwendet werden.\n",
    "\n",
    "PyTorch Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout_layer = nn.Dropout(0.2)\n",
    "#Angewandt in einem Netzwerk mit Input x:\n",
    "\n",
    "# n1   = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "# n2   = nn.Conv2d(out_channels, out_channels, kernel_size)\n",
    "# drop = nn.Dropout2d(0.2)\n",
    "# x = n2(drop(n1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Optimierungsalgorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie im vorherigen Tutorial erklärt, lassen sich verschiedene Optimierungsvarianten verwenden, die adaptive oder nicht-adaptiver Natur sein können. Daher hier eine simple Auflistung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optim.Adam(), optim.SGD(momentum=0.9), optim.Adadelta, optim.RMSprop, optim.Adamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Batch-Normalisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch-Normalization ist eine vergleichsweise neue Inklusion in die Welt der Netzwerke. Sie baut darauf auf das in Netzwerken die Verwendung von Minibatches zur Approximation des Gradienten folgendes Problem mit sich zieht:\n",
    "\n",
    "Von einem Neuron in einer Schicht zur anderen können Aktivierungswerte starke Änderungen erfahren, die aber nicht zwingend der Verteilung entsprechen, derer sich die Eingangswerte unterziehen. Um dem Problem entgegenzuwirken, führt Batch-Normalisierung pro Schicht und Neuron lernbare Varianz- und Mittelwert-parameter ein, welche Aktivierung auf ein ähnliches Niveau skalieren. \n",
    "\n",
    "Dabei werden diese Parameter über den Minibatch abgeschätzt und mit jeder Trainingsiteration upgedatet. Für eine verlässliche Abschätzung ist es daher wichtig, dass Batchsizes groß genug gewählt werden ($8-16$ und aufwärts).\n",
    "\n",
    "In einem Netzwerk wird das wie folgt eingebaut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bn = nn.BatchNorm2d(filter_in_next_layer)\n",
    "\n",
    "# n1   = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "# n2   = nn.Conv2d(out_channels, out_channels, kernel_size)\n",
    "# bn   = nn.BatchNorm2d(out_channels)\n",
    "# x = n2(bn(n1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Aktivierungsfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ebenso angesprochen waren die vielen Optionen für Aktivierungsfunktionen, die hier lediglich der Vollständigkeitshalber erwähnt werden sollen. Neben `ReLU` fallen darunter auch `LeakyReLU` (kleine Steigung bei Werten unter Null), `ParametricReLU` mit lernbarer Steigung für Werte unter Null) und viele andere Optionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.ReLU, F.relu(), F.leaky_relu(), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Hyperparameter-Optimmierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final soll nochmal angemerkt werden, dass die Lernfähigkeit des Netzwerkes auch stark von der Wahl der Trainingshyperparameter abhängt. Darunter fallen beispielsweise:\n",
    "\n",
    "* Lernrate\n",
    "* Batchsize\n",
    "* Trainings-Validierungseinteilung\n",
    "* Wahrscheinlichkeit mit welcher Bilder aus den entsprechenden Klassen dem Netzwerk präsentiert werden\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel des ganzen Tages ist es, mindestens 3/4 verschiedene Netzwerkstrukturen zu trainieren, Trainings- und Validierungskurven zu speichern und zu vergleichen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
