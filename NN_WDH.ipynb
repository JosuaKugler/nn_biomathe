{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronale Netzwerke - Wiederholung\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typen neuronaler Netzwerke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fully-Connected Neural Networks (FCN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein __FCN__ (oder neuronale Netzwerke im Allgemeinen) kann als Sequenz spezifischer Schichten beschrieben werden. Diese Schichten, entsprechend der Position als _input_-, _output_- und _hidden layer_ bezeichnet, sind Kollektionen von Neuronen (siehe Bild). \n",
    "<img src=\"Bilder/fnc.jpeg\">\n",
    "Jedes Neuron hat bei einem __FCN__ eine Verbindung zu allen vorhergehenden und nachfolgenden Neuronen. Alle eingehenden (und die entsprechend ausgehenden) Verknüpfungen können beschrieben werden wie in folgendem Bild:\n",
    "<img src=\"Bilder/single_neuron.jpg\">\n",
    "Jede Verknüpfung hat ein kennzeichnendes Gewicht, welches dem entsprechenden Eingangssignal eine Wichtigkeit zuordnet. Diese Miniprodukte werden dann summiert und durch eine Aktivierungsfunktion $f$ geschickt.\n",
    "Somit führt jedes Neuron eine mathematische Operation der Form\n",
    "\n",
    "\\begin{equation}\n",
    "y = f\\left( b + \\sum_{i=1}^n w_ix_i \\right)\n",
    "\\end{equation}\n",
    "\n",
    "durch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein __CNN__ ist eine Sammlung verschiedener _Kernels_ oder _Filter_ - kleine \"Pakete\" mit Gewichten, welche über das Bild geschoben (_gefaltet_) werden. Ziel ist es, das jedes einzelne Paket Pixelgruppen identifiziert, z.B. kleine Ecken und Linien in der ersten Schicht und komplizierte, kombinierte Strukturen in den Folgeschichten. Dies lässt sich gut an einem generellen Aufbaubeispiel verdeutlichen, z.B. hier:\n",
    "<img src=\"Bilder/cnn.png\">\n",
    "\n",
    "oder hier:\n",
    "\n",
    "<img src=\"Bilder/cnn2.png\">\n",
    "\n",
    "---\n",
    "\n",
    "Die _Kernel_ werden dabei entsprechenden folgendem Bild über das Bild geschoben um sog. __feature maps__ zu generieren; funktionale Bilder welche die Auftrittswahrscheinlichkeit eines vom entsprechenden _Kernel_ codierten _features_ (Eigenschaft) am entsprechenden Ort angeben:\n",
    "\n",
    "<img src=\"Bilder/conv_pic_example.png\">\n",
    "\n",
    "Häufig auftretend in solchen Strukturen sind __Pooling Layer__ , welche die vorhergehenden _feature maps_ zusammenfassen um Platz zu speichern und das Training zu beschleunigen. Ein solches _Layer_ ist definiert durch eine _Kernelgröße_, welche wie bei normalen _CNN_-Schichten über das Bild geschoben werden und dabei entsprechende Zusammenfassungsoperation durchführen, z.B. das Maximum oder das arithmetische Mittel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umsetzung in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein solches Netzwerk effektiv und vor allem einfach implementieren zu können, verwenden wir die __PyTorch__-Bibliothek (Installationsinformationen siehe vorheriges Tutorial).\n",
    "\n",
    "Für ein _FCN_ sieht das beispielsweise so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "#torch.nn ist die Sammlung aller generellen Funktionen \n",
    "#eines neuronalen Netzwerkes, daher auch die Abküruzung nn.\n",
    "\n",
    "# class FCN_Base(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(FCN_Base,self).__init__()\n",
    "#         self.fcn1 = nn.Linear(784,30)\n",
    "#         self.fcn2 = nn.Linear(30,30)\n",
    "#         self.fcn3 = nn.Linear(30,10)\n",
    "#         self.akt_func = nn.Softmax(dim=1)\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = F.relu(self.fcn1(x))\n",
    "#         x = F.relu(self.fcn2(x))\n",
    "#         x = self.akt_func(self.fcn3(x))\n",
    "#         return x\n",
    "    \n",
    "#ODER\n",
    "\n",
    "# FCN_Base_2 = torch.nn.Sequential(\n",
    "#              torch.nn.Linear(784, 30), # Erste/Zweite Schicht: 784 Eingangsneuronen zu 30 \"versteckten\" Neuronen\n",
    "#              torch.nn.ReLU(),          # Aktivierungsfunktion\n",
    "#              torch.nn.Linear(30, 30),  # Zweite/Erste Schicht: 30 \"versteckte\" Neuronen gehen über zu 10 Ausgangsneuronen.\n",
    "#              torch.nn.ReLU(),\n",
    "#              torch.nn.Linear(30,10),\n",
    "#              torch.nn.Softmax(dim=1)   # Ausgangsaktivierungsfunktion. Siehe vorheriges Tutorial.\n",
    "#              )\n",
    "\n",
    "#Sowie für CNNs:\n",
    "\n",
    "class CNN_Base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Base,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, kernel_size=3)  # 26x26\n",
    "        self.conv2 = nn.Conv2d(30, 50, kernel_size=3) # 24x24\n",
    "        self.bn1 = nn.BatchNorm2d(50)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=3,padding=1)  # 12x12\n",
    "        self.conv4 = nn.Conv2d(100, 100, kernel_size=3,padding=1)  # 12x12\n",
    "        self.bn2 = nn.BatchNorm2d(100)\n",
    "        self.conv5 = nn.Conv2d(100, 150, kernel_size=3,padding=1) # 6x6        \n",
    "        self.conv6 = nn.Conv2d(150, 50, kernel_size=3,padding=1)# 6x6                \n",
    "        self.fc1 = nn.Linear(1800, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "        self.dp1 = nn.Dropout2d(0.2)\n",
    "        self.dp2 = nn.Dropout2d(0.2)\n",
    "        \n",
    "        self.out_act = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(F.max_pool2d(self.bn1(self.conv2(self.conv1(x))), 2))\n",
    "        x = self.dp1(x)\n",
    "        x = F.leaky_relu(F.max_pool2d(self.bn2(self.conv4(self.conv3(x))), 2))\n",
    "        x = self.dp2(x)\n",
    "        x = F.leaky_relu(self.conv6(self.conv5(x)))\n",
    "        x = x.view(-1, 1800)   #Hier ändern wir Bild- zu Vektorformat\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))        \n",
    "        x = self.fc3(x)\n",
    "        return self.out_act(x)\n",
    "\n",
    "#ODER\n",
    "\n",
    "# class CNN_Base_2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         self.conv_teil = nn.Sequential(\n",
    "#                          nn.Conv2d(1,10,3),\n",
    "#                          nn.Conv2d(10,20,3),\n",
    "#                          nn.MaxPool2d(2),\n",
    "#                          nn.ReLU(),\n",
    "#                          nn.Conv2d(20,30,3),\n",
    "#                          nn.Conv2d(30,30,3),\n",
    "#                          nn.MaxPool2d(2),\n",
    "#                          nn.ReLU(),\n",
    "#                          nn.Conv2d(30,50,3),\n",
    "#                          nn.Conv2d(50,50,3),\n",
    "#                          nn.ReLU())\n",
    "#         self.fcn_teil =  nn.Sequential(\n",
    "#                          nn.Linear(1800,150),\n",
    "#                          nn.ReLU(),\n",
    "#                          nn.Linear(150,50),\n",
    "#                          nn.ReLU(),\n",
    "#                          nn.Linear(50,10),\n",
    "#                          nn.Softmax(dim=1))\n",
    "#     def forward(self,x):\n",
    "#         x = self.conv_teil(x)\n",
    "#         x = x.view(-1,1800)\n",
    "#         x = self.fcn_teil(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das allgemeine Training können wir das entsprechende Skript des letzten Tutorials verwenden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generelle Funktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class MNIST_Data_Provider(Dataset):\n",
    "    def __init__(self, all_image_paths, all_image_labels):\n",
    "        super(MNIST_Data_Provider, self).__init__()\n",
    "\n",
    "        self.all_image_paths, self.all_image_labels = all_image_paths, all_image_labels\n",
    "        self.transform_to_torch_tensor = transforms.ToTensor()\n",
    "        self.hot_list = np.eye(10).astype(int)     \n",
    "        \n",
    "    def one_hot(self, label):\n",
    "        return self.hot_list[label]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        loaded_image    = Image.open(self.all_image_paths[idx])\n",
    "        label_for_image = self.all_image_labels[idx]\n",
    "        \n",
    "        return self.transform_to_torch_tensor(loaded_image), label_for_image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_image_paths)\n",
    "    \n",
    "\n",
    "def get_image_paths(path_to_folder):\n",
    "    all_image_paths = []\n",
    "    all_labels      = []\n",
    "    for numberpath in os.listdir(path_to_folder):\n",
    "        if numberpath != \".DS_Store\" and '_' not in numberpath:\n",
    "            avail_img_paths = [x for x in os.listdir(path_to_folder+\"/\"+numberpath) if '._' not in x]\n",
    "            all_image_paths.extend([path_to_folder+\"/\"+numberpath+\"/\"+x for x in avail_img_paths])\n",
    "            all_labels.extend([int(numberpath) for _ in range(len(avail_img_paths))])\n",
    "    return all_image_paths, all_labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainings-Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphikkarte vorhanden: False\n",
      "Training in Epoch 0...\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ba2fc61acb4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mtrain_avg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mtrain_avg_acc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_datagen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# ensure that the worker exits on process exit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\"\"\" Graphikkarte benutzen? \"\"\"\n",
    "print('Graphikkarte vorhanden: {}'.format(torch.cuda.is_available()))\n",
    "gk_nutzen   = True\n",
    "gk_vorhanden= torch.cuda.is_available()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Hyperparameter \"\"\"\n",
    "batch_size = 64\n",
    "n_epochs   = 5\n",
    "learning_rate = 0.0002\n",
    "train_validation_split = 0.8\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \"\"\" Aufsetzen der Datengeneratoren \"\"\"\n",
    "    path_to_MNIST_dataset = \"trainingSet\"\n",
    "\n",
    "    all_image_paths, all_image_labels = get_image_paths(path_to_MNIST_dataset)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(all_image_paths)\n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(all_image_labels)\n",
    "\n",
    "    split_idx = int(len(all_image_paths)*train_validation_split)\n",
    "\n",
    "    training_img_paths = all_image_paths[:split_idx]\n",
    "    training_labels    = all_image_labels[:split_idx]\n",
    "    train_dataset = MNIST_Data_Provider(training_img_paths, training_labels)\n",
    "    train_datagen = DataLoader(train_dataset, batch_size=batch_size,drop_last=True, shuffle=True, num_workers=1)\n",
    "\n",
    "    validation_img_paths = all_image_paths[split_idx:]\n",
    "    validation_labels    = all_image_labels[split_idx:]\n",
    "    val_dataset = MNIST_Data_Provider(validation_img_paths, validation_labels)\n",
    "    val_datagen = DataLoader(val_dataset, batch_size=batch_size, drop_last=True, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Laden des Netzes, Aufsetzen des Optimierers\"\"\"\n",
    "    Net = CNN_Base()\n",
    "    #Net.load_state_dict(torch.load(_pfad_zum_speicherplatz_mit_namen))\n",
    "    if gk_nutzen and gk_vorhanden:\n",
    "        _ = Net.cuda()\n",
    "\n",
    "    #Oder: FCN_Base, FCN_Base_2, CNN_Base_2\n",
    "    optimizer = optim.Adam(Net.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer,gamma=0.2,step_size=10)\n",
    "\n",
    "\n",
    "    \"\"\" Training & Validierung \"\"\"\n",
    "    best_val_score = 0\n",
    "    data_coll = {\"t_acc\":[], \"v_acc\":[]}\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Training in Epoch {}...\".format(epoch))\n",
    "\n",
    "        \"\"\" Hier startet das Training! \"\"\"\n",
    "        Net.train()\n",
    "\n",
    "        train_avg_loss = 0\n",
    "        train_avg_acc  = 0\n",
    "        for idx, (img,label) in enumerate(train_datagen):\n",
    "            img, label = Variable(img), Variable(label)\n",
    "\n",
    "            if gk_nutzen and gk_vorhanden:\n",
    "                img,label = img.cuda(), label.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            ### Für FCNs\n",
    "            #output = Net(img.view(batch_size,-1))\n",
    "            output = Net(img)\n",
    "\n",
    "            loss = F.cross_entropy(output, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            correct_guesses = output.data.max(1)[1].eq(label.data).sum()\n",
    "\n",
    "            train_avg_loss += loss.data[0]\n",
    "            train_avg_acc  += correct_guesses\n",
    "\n",
    "            if idx%100==0 and idx!=0:\n",
    "                print(\"\\t T-Progress: [{}/{}]\".format(idx+1,len(train_datagen)))\n",
    "\n",
    "        train_avg_loss = train_avg_loss*1./(batch_size*len(train_datagen))\n",
    "        train_avg_acc  = train_avg_acc*1./(batch_size*len(train_datagen))\n",
    "\n",
    "        data_coll[\"t_acc\"].append(train_avg_acc)\n",
    "\n",
    "        \"\"\" Hier startet die Validierung \"\"\"\n",
    "        Net.eval()\n",
    "\n",
    "        val_avg_acc = 0\n",
    "\n",
    "        for idx, (img,label) in enumerate(val_datagen):\n",
    "            img, label = Variable(img), Variable(label)\n",
    "\n",
    "            if gk_nutzen and gk_vorhanden:\n",
    "                img, label = img.cuda(), label.cuda()\n",
    "\n",
    "            #output = Net(img.view(batch_size,-1))\n",
    "            output = Net(img)\n",
    "            correct_guesses = output.data.max(1)[1].eq(label.data).sum()\n",
    "\n",
    "            val_avg_acc  += correct_guesses\n",
    "\n",
    "            if idx%100==0 and idx!=0:\n",
    "                print(\"\\t V-Progress: [{}/{}]\".format(idx+1,len(val_datagen)))    \n",
    "\n",
    "        val_avg_acc = val_avg_acc*1./(batch_size*len(val_datagen))\n",
    "        data_coll[\"v_acc\"].append(val_avg_acc)    \n",
    "        if val_avg_acc>best_val_score:\n",
    "            best_val_score=val_avg_acc\n",
    "\n",
    "        print(\"Results: T-Loss {0:2.5f} | T-Acc {1:3.4f}% | V-Acc {2:3.4f}% | BVS: {3:3.4f}\".format(train_avg_loss, train_avg_acc*100., val_avg_acc*100., best_val_score*100.))\n",
    "    #torch.save(Net.state_dict(), _pfad_zum_speicherplatz_mit_namen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f,ax = plt.subplots(1)\n",
    "ax.plot(data_coll[\"v_acc\"],'r')\n",
    "ax.set_ylabel('Validation')\n",
    "axx = ax.twinx()\n",
    "axx.plot(data_coll[\"t_acc\"])\n",
    "axx.set_ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Net.state_dict(), os.getcwd()+'/Netzwerk_Gewichte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nacht der Forschung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einzelnes Bild vorhersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_getDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-23a8ef474ca4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[0mNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_Base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m \u001b[0mNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/Netzwerk_Gewichte'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 deserialized_objects[root_key] = restore_location(\n\u001b[1;32m--> 389\u001b[1;33m                     data_type(size), location)\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, async)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprev_idx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_getDevice'"
     ]
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### PYTHON FUNKTIONEN UM DIE ZAHLBILDER ZU LADEN\n",
    "class MNIST_Data_Provider(Dataset):\n",
    "    def __init__(self, all_image_paths, all_image_labels):\n",
    "        super(MNIST_Data_Provider, self).__init__()\n",
    "\n",
    "        self.all_image_paths, self.all_image_labels = all_image_paths, all_image_labels\n",
    "        self.transform_to_torch_tensor = transforms.ToTensor()\n",
    "        self.hot_list = np.eye(10).astype(int)     \n",
    "        \n",
    "    def one_hot(self, label):\n",
    "        return self.hot_list[label]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        loaded_image    = Image.open(self.all_image_paths[idx])\n",
    "        label_for_image = self.all_image_labels[idx]\n",
    "        \n",
    "        return self.transform_to_torch_tensor(loaded_image), label_for_image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_image_paths)\n",
    "    \n",
    "\n",
    "def get_image_paths(path_to_folder):\n",
    "    all_image_paths = []\n",
    "    all_labels      = []\n",
    "    for numberpath in os.listdir(path_to_folder):\n",
    "        if numberpath != \".DS_Store\" and '_' not in numberpath:\n",
    "            avail_img_paths = [x for x in os.listdir(path_to_folder+\"/\"+numberpath) if '._' not in x]\n",
    "            all_image_paths.extend([path_to_folder+\"/\"+numberpath+\"/\"+x for x in avail_img_paths])\n",
    "            all_labels.extend([int(numberpath) for _ in range(len(avail_img_paths))])\n",
    "    return all_image_paths, all_labels \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################### AUFSETZEN DER DATEN-LADER\n",
    "train_validation_split = 0.8\n",
    "\n",
    "\n",
    "\"\"\" Aufsetzen der Datengeneratoren \"\"\"\n",
    "path_to_MNIST_dataset = \"trainingSet\"\n",
    "\n",
    "all_image_paths, all_image_labels = get_image_paths(path_to_MNIST_dataset)\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(all_image_paths)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(all_image_labels)\n",
    "\n",
    "split_idx = int(len(all_image_paths)*train_validation_split)\n",
    "\n",
    "training_img_paths = all_image_paths[:split_idx]\n",
    "training_labels    = all_image_labels[:split_idx]\n",
    "train_dataset = MNIST_Data_Provider(training_img_paths, training_labels)\n",
    "train_datagen = DataLoader(train_dataset, batch_size=batch_size,drop_last=True, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############## NETZWERK LADEN\n",
    "class CNN_Base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Base,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, kernel_size=3)  # 26x26\n",
    "        self.conv2 = nn.Conv2d(30, 50, kernel_size=3) # 24x24\n",
    "        self.bn1 = nn.BatchNorm2d(50)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=3,padding=1)  # 12x12\n",
    "        self.conv4 = nn.Conv2d(100, 100, kernel_size=3,padding=1)  # 12x12\n",
    "        self.bn2 = nn.BatchNorm2d(100)\n",
    "        self.conv5 = nn.Conv2d(100, 150, kernel_size=3,padding=1) # 6x6        \n",
    "        self.conv6 = nn.Conv2d(150, 50, kernel_size=3,padding=1)# 6x6                \n",
    "        self.fc1 = nn.Linear(1800, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "        self.dp1 = nn.Dropout2d(0.2)\n",
    "        self.dp2 = nn.Dropout2d(0.2)\n",
    "        \n",
    "        self.out_act = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(F.max_pool2d(self.bn1(self.conv2(self.conv1(x))), 2))\n",
    "        x = self.dp1(x)\n",
    "        x = F.leaky_relu(F.max_pool2d(self.bn2(self.conv4(self.conv3(x))), 2))\n",
    "        x = self.dp2(x)\n",
    "        x = F.leaky_relu(self.conv6(self.conv5(x)))\n",
    "        x = x.view(-1, 1800)   #Hier ändern wir Bild- zu Vektorformat\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))        \n",
    "        x = self.fc3(x)\n",
    "        return self.out_act(x)\n",
    "    \n",
    "######## NETZWERK AUFBAUEN UND MIT VORTRAINIERTEN GEWICHTEN VERSEHEN\n",
    "Net = CNN_Base()\n",
    "_ = Net.eval()\n",
    "Net.load_state_dict(torch.load(os.getcwd()+'/Netzwerk_Gewichte'))\n",
    "\n",
    "\n",
    "    \n",
    "######## VORHERSAGE TREFFEN fuer ein einzelnes Bild\n",
    "input_bild_batch, label_batch = next(iter(train_datagen))\n",
    "idx = np.random.randint(len(label_batch))\n",
    "input_bild = input_bild_batch[idx]\n",
    "label      = label_batch[idx]\n",
    "input_net  = Variable(input_bild)\n",
    "prediction = Net(input_net.unsqueeze(1))\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(input_bild.numpy()[0,:],cmap='gray')\n",
    "plt.title('Wert: {} | Vorhersage: {}'.format(label, np.argmax(prediction.data.numpy())))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier noch eine wichtige Erweiterung: Wenn die Gewichte des Netzwerk gespeichert werden sollen, um sie irgendwann nochmal wieder zu verwenden, bedient man sich einfach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(Net.state_dict(), _pfad_zum_speicherplatz_mit_namen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein Netzwerk mit den entsprechenden Gewichten auszustatten, verwendet man:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net.load_state_dict(torch.load(_pfad_zum_speicherplatz_mit_namen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wichtig: Die Netzwerkstruktur muss die Gleiche sein, um sie mit Gewichten ausstatten zu können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einige neue extra Methoden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unter <http://pytorch.org/docs/master/nn.html#> finden sich viele weitere Möglichkeiten, die Performance des Netzwerkes zu verbessern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regularisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(Net.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout_layer = nn.Dropout(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Optimierungsalgorithmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optim.Adam(), optim.SGD(momentum=0.9), optim.Adadelta, optim.RMSprop, optim.Adamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Batch-Normalisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bn = nn.BatchNorm2d(filter_in_next_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Aktivierungsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.ReLU, F.relu(), F.leaky_relu(), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter-Optimmierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate, batchsize, usw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel des ganzen Tages ist es, mindestens 3/4 verschiedene Netzwerkstrukturen zu trainieren, Trainings- und Validierungskurven zu speichern und zu vergleichen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
